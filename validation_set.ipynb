{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda: Quadro M4000 (0000:00:05.0)\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "from tools import *\n",
    "from image_processing import *\n",
    "from optparse import OptionParser\n",
    "\n",
    "from model import *\n",
    "\n",
    "from keras import backend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limit = 11500\n",
    "backend.set_image_dim_ordering('th')\n",
    "IMG_SIZE = 224\n",
    "classes = get_classes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition des fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pictures(path, filename, limit, forceProcess = False):\n",
    "    if os.path.exists(filename) and not forceProcess:\n",
    "        preprocessed_imgs = restore(filename)\n",
    "        print (\"Done.\")\n",
    "    else:\n",
    "        print (\"Preprocessing....\")\n",
    "        preprocessed_imgs = preprocess_imgs(path, IMG_SIZE, limit = limit)\n",
    "        store(preprocessed_imgs, filename)\n",
    "    return preprocessed_imgs\n",
    "        \n",
    "\n",
    "def load_dataset(path, filename, limit, forceProcess = False):\n",
    "    cats_file = filename + 'cats.pckl'\n",
    "    dogs_file = filename + 'dogs.pckl'\n",
    "    print (\"Loading cats images:\")\n",
    "    preprocessed_cats = load_pictures(path, cats_file, limit, forceProcess)\n",
    "    print (\"Loading dogs images:\")\n",
    "    preprocessed_dogs = load_pictures(path, dogs_file, limit, forceProcess)\n",
    "    return preprocessed_valid_cats, preprocessed_valid_dogs\n",
    "    \n",
    "\n",
    "def load_validation_pictures(limit_valid, forceProcess = False):\n",
    "    return load_dataset('valid', 'preprocessed_validation_', limit_valid, forceProcess = False)\n",
    "\n",
    "\n",
    "def load_train_pictures(limit, forceProcess = False):\n",
    "    return load_dataset('train', 'preprocessed_', limit_valid, forceProcess = False)\n",
    "\n",
    "def construct_input_matrix(preprocessed_cats, preprocessed_dogs):   \n",
    "    X = np.concatenate((preprocessed_cats, preprocessed_dogs), axis = 0)\n",
    "    X = np.swapaxes(X, 1, 3)\n",
    "    return X\n",
    "\n",
    "def create_expected_output(limit):\n",
    "    \"\"\"labelling the data: cats = [1 0] and dogs = [0 1]\"\"\"\n",
    "    zeros = np.zeros((limit, 1))\n",
    "    ones  = np.ones((limit, 1))\n",
    "    Ycats = np.array((ones, zeros))\n",
    "    Ydogs = np.array((zeros, ones))\n",
    "\n",
    "    Y = np.concatenate((Ycats, Ydogs), axis=1)\n",
    "    Y = np.swapaxes(Y, 0, 1).squeeze()\n",
    "    return Y\n",
    "\n",
    "\n",
    "\n",
    "def predict_cat_dog_at_index(model, input_array, index, limit = limit):\n",
    "    print (\"Predict a cat: \")\n",
    "    cat_prediction = model.predict(np.array([input_array[index,:,:]])).argmax(axis = 1)[0]\n",
    "    print ( cat_prediction, classes[cat_prediction] )\n",
    "\n",
    "    print (\"Predict a dog: \")\n",
    "    dog_prediction = model.predict(np.array([input_array[limit + index,:,:]])).argmax(axis = 1)[0]\n",
    "    print (dog_prediction, classes[dog_prediction])\n",
    "    \n",
    "    \n",
    "def convolutional_output(X, convolutional_model, forceProcess = False, filename = 'conv_output.pckl'):\n",
    "    if os.path.exists('conv_output.pckl') and not forceProcess:\n",
    "        conv_output = restore('conv_output.pckl')\n",
    "    else:\n",
    "        conv_output = convolutional_model.predict(X)\n",
    "        store(conv_output, 'conv_output.pckl')\n",
    "    return conv_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cats images:\n",
      "Done.\n",
      "Loading dogs images:\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "preprocessed_cats, preprocessed_dogs = load_train_pictures(limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23000, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "Y = create_expected_output(limit)\n",
    "X = construct_input_matrix( preprocessed_cats, preprocessed_dogs )\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct and test Vgg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(IMG_SIZE)\n",
    "for layer in model.layers: layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict a cat: \n",
      "(281, u'tabby')\n",
      "Predict a dog: \n",
      "(243, u'bull_mastiff')\n"
     ]
    }
   ],
   "source": [
    "predict_cat_dog_at_index(model, X, 4789)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sepate convolutional layers and dense layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of layers : 38, only the 6 last layers are dense layers\n",
      "Total number of convolutional layers : 32\n",
      "Total number of dense layers : 5\n"
     ]
    }
   ],
   "source": [
    "print (\"Total number of layers : {}, only the 6 last layers are dense layers\".format(len(model.layers)))\n",
    "\n",
    "def no_process(x):\n",
    "    # return x[:, ::-1]\n",
    "    return x\n",
    "\n",
    "def separate_models(model, nb_dense = 6):\n",
    "    nb_layers = len(model.layers)\n",
    "    dense_model = Sequential()\n",
    "    dense_model.add(Lambda(no_process, input_shape=(512, 7, 7), output_shape=(512, 7, 7) ))\n",
    "    for layer in model.layers[-6:]:\n",
    "        if \"dropout\" not in layer.name:\n",
    "            dense_model.add(layer)\n",
    "    convolutional_model = Sequential(model.layers[:nb_layers - 6])\n",
    "    print (\"Total number of convolutional layers : {}\".format(len(convolutional_model.layers)))\n",
    "    print (\"Total number of dense layers : {}\".format(len(dense_model.layers)))\n",
    "    return dense_model, convolutional_model\n",
    "\n",
    "dense_model, convolutional_model = separate_models(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convolutional_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_4 (Lambda)            (None, 512, 7, 7)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 123,642,856\n",
      "Trainable params: 0\n",
      "Non-trainable params: 123,642,856\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dense_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_output = convolutional_output(X, convolutional_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict a cat: \n",
      "(281, u'tabby')\n",
      "Predict a dog: \n",
      "(243, u'bull_mastiff')\n"
     ]
    }
   ],
   "source": [
    "# check that the output still makes sense\n",
    "predict_cat_dog_at_index(dense_model, conv_output, 4789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im = Image.fromarray(np.swapaxes(X[12,:,:], 0 , 2) )\n",
    "# im = Image.open(\"train/cats/cat.50.jpg\")\n",
    "im.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cats images:\n",
      "Done.\n",
      "Loading dogs images:\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "limit_valid = 1000\n",
    "\n",
    "preprocessed_valid_cats, preprocessed_valid_dogs = load_validation_pictures(limit_valid)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_4 (Lambda)            (None, 512, 7, 7)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 2002      \n",
      "=================================================================\n",
      "Total params: 123,644,858\n",
      "Trainable params: 2,002\n",
      "Non-trainable params: 123,642,856\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dense_model.add(Dense(2, activation='softmax', input_shape=(1000,)))\n",
    "dense_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_valid = create_expected_output(limit_valid)\n",
    "X_valid = construct_input_matrix(preprocessed_valid_cats, preprocessed_valid_dogs)\n",
    "\n",
    "Xtrain = X[0:2000,:,:,:]\n",
    "Ytrain = Y[0:2000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_valid_output = convolutional_output(X, convolutional_model, filename = 'conv_valid_output.pckl')\n",
    "\n",
    "\n",
    "sample_valid_output = conv_valid_output[0:2000,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_input_output(X, Y):\n",
    "    def generate_arrays():\n",
    "        for i in range(len(X)):\n",
    "            yield (X[50*i:50*i+50,:,:,:],Y[50*i:50*i+50,:])\n",
    "    return generate_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "23000/23000 [==============================] - 8s - loss: 0.2225 - acc: 0.9672     \n",
      "Epoch 2/10\n",
      "23000/23000 [==============================] - 8s - loss: 0.2035 - acc: 0.9700     \n",
      "Epoch 3/10\n",
      "23000/23000 [==============================] - 8s - loss: 0.1872 - acc: 0.9725     \n",
      "Epoch 4/10\n",
      "23000/23000 [==============================] - 8s - loss: 0.1729 - acc: 0.9741     \n",
      "Epoch 5/10\n",
      "23000/23000 [==============================] - 8s - loss: 0.1602 - acc: 0.9756     \n",
      "Epoch 6/10\n",
      "23000/23000 [==============================] - 8s - loss: 0.1480 - acc: 0.9773     \n",
      "Epoch 7/10\n",
      "23000/23000 [==============================] - 8s - loss: 0.1383 - acc: 0.9784     \n",
      "Epoch 8/10\n",
      "23000/23000 [==============================] - 8s - loss: 0.1290 - acc: 0.9792     \n",
      "Epoch 9/10\n",
      "23000/23000 [==============================] - 8s - loss: 0.1201 - acc: 0.9804     \n",
      "Epoch 10/10\n",
      "23000/23000 [==============================] - 8s - loss: 0.1124 - acc: 0.9811     \n"
     ]
    }
   ],
   "source": [
    "dense_model.compile(\n",
    "        # loss='binary_crossentropy',\n",
    "       #optimizer=SGD(lr=10.0),\n",
    "          #optimizer=RMSprop(),\n",
    "       optimizer=Adam(lr=0.0001),\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "dense_model.layers[-2].trainable = True\n",
    "\n",
    "if os.path.exists('dense_model.h5'):\n",
    "    dense_model.load_weights('dense_model.h5')\n",
    "    \n",
    "dense_model.fit(conv_output ,Y)\n",
    "\n",
    "dense_model.save_weights(\"dense_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model.compile(\n",
    "        # loss='binary_crossentropy',\n",
    "       #optimizer=SGD(lr=10.0),\n",
    "          #optimizer=RMSprop(),\n",
    "       optimizer=Adam(lr=0.0001),\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "\n",
    "if os.path.exists('dense_model.h5'):\n",
    "    model.load_weights('dense_model.h5')\n",
    "    \n",
    "dense_model.fit_generator(generate_input_output(convolutional_output, Y), \n",
    "                          steps_per_epoch=40, epochs=1, validation_steps = 40, \n",
    "                          validation_data = (sample_valid_output, Y_valid) )\n",
    "dense_model.save_weights(\"dense_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "test_set_size= 12500\n",
    "preprocessed_test_set = load_pictures('test', 'preprocessed_test_set.pckl', test_set_size, forceProcess = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12500, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "X_test = np.swapaxes(preprocessed_test_set, 1, 3)\n",
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12500, 512, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "test_conv_output = convolutional_output(X_test, convolutional_model, forceProcess = False, filename = 'test_conv_output.pckl')\n",
    "print test_conv_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.83419549,  0.16580449]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_model.predict(convolutional_model.predict(np.array([X_test[12]])))\n",
    "dense_model.predict(np.array([test_conv_output[12]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.83685905  0.16314095]]\n",
      "[[ 0.83685905  0.16314095]]\n",
      "[[ 0.8367421   0.16325796]]\n",
      "[[ 0.83685935  0.16314064]]\n"
     ]
    }
   ],
   "source": [
    "print dense_model.predict(convolutional_model.predict(np.array([X[5]])))\n",
    "print dense_model.predict(np.array([conv_output[5]]))\n",
    "\n",
    "print dense_model.predict(convolutional_model.predict(np.array([X_valid[50]])))\n",
    "print dense_model.predict(np.array([conv_valid_output[50]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12500, 2)\n"
     ]
    }
   ],
   "source": [
    "test_set_predictions = dense_model.predict(test_conv_output)\n",
    "print test_set_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_string = \"id,label\\n\"\n",
    "for i,prediction in enumerate(test_set_predictions):\n",
    "    submission_string = submission_string + str(i+1) + \",\" + str(prediction[1]) + \"\\n\"\n",
    "\n",
    "    \n",
    "submission_file = open(\"Submission.csv\", \"w\")\n",
    "submission_file.write(submission_string)\n",
    "submission_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
